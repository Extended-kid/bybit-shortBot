from pybit.unified_trading import HTTP
import pandas as pd
import numpy as np
from pathlib import Path
from typing import Dict, List, Optional
import logging
from datetime import datetime, timedelta
import time
from concurrent.futures import ThreadPoolExecutor, as_completed
from tqdm import tqdm

logger = logging.getLogger(__name__)

class BybitDataLoader:
    """–ó–∞–≥—Ä—É–∑—á–∏–∫ –¥–∞–Ω–Ω—ã—Ö –∏–∑ Bybit API"""
    
    def __init__(self, cache_dir: str = './cache'):
        self.cache_dir = Path(cache_dir)
        self.cache_dir.mkdir(exist_ok=True)
        
        # Bybit API –∫–ª–∏–µ–Ω—Ç
        self.session = HTTP(testnet=False)
        
        # –ú–∞–ø–ø–∏–Ω–≥ –∏–Ω—Ç–µ—Ä–≤–∞–ª–æ–≤
        self.interval_map = {
            '1m': '1',
            '3m': '3',
            '5m': '5',
            '15m': '15',
            '30m': '30',
            '1h': '60',
            '2h': '120',
            '4h': '240',
            '6h': '360',
            '12h': '720',
            '1d': 'D',
            '1w': 'W',
            '1M': 'M'
        }
        
    def get_usdt_perpetual_symbols(self, limit: int = None) -> List[str]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ —Å–ø–∏—Å–∫–∞ USDT perpetual —Ñ—å—é—á–µ—Ä—Å–æ–≤"""
        try:
            print("üîç –ü–æ–ª—É—á–∞—é —Å–ø–∏—Å–æ–∫ USDT perpetual...")
            
            response = self.session.get_instruments_info(
                category="linear",  # linear = USDT perpetual
                limit=1000
            )
            
            if response['retCode'] == 0:
                symbols = []
                for item in response['result']['list']:
                    # USDT perpetual: quoteCoin = USDT, contractType = LinearPerpetual
                    if item['quoteCoin'] == 'USDT' and item.get('contractType') == 'LinearPerpetual':
                        symbols.append(item['symbol'])
                
                if limit:
                    symbols = symbols[:limit]
                
                print(f"‚úÖ –ù–∞–π–¥–µ–Ω–æ {len(symbols)} USDT perpetual")
                return symbols
            else:
                print(f"‚ùå –û—à–∏–±–∫–∞ API: {response['retMsg']}")
                return []
                
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ —Å–∏–º–≤–æ–ª–æ–≤: {e}")
            return []
    
    def get_klines(self, symbol: str, interval: str, start_date: str, end_date: str) -> Optional[pd.DataFrame]:
        """–ó–∞–≥—Ä—É–∑–∫–∞ –í–°–ï–• —Å–≤–µ—á–µ–π –∑–∞ –ø–µ—Ä–∏–æ–¥ —Å –ø—Ä–∞–≤–∏–ª—å–Ω–æ–π –ø–∞–≥–∏–Ω–∞—Ü–∏–µ–π"""
        
        interval_str = self.interval_map.get(interval, '15')
        
        start_dt = pd.to_datetime(start_date)
        end_dt = pd.to_datetime(end_date)
        
        start_ms = int(start_dt.timestamp() * 1000)
        end_ms = int(end_dt.timestamp() * 1000)
        
        all_klines = []
        current_end = end_ms
        batch_limit = 1000
        
        print(f"  –ó–∞–≥—Ä—É–∑–∫–∞ {symbol}...")
        
        with tqdm(desc=f"{symbol}", leave=False, position=1) as pbar:
            while current_end > start_ms:
                try:
                    response = self.session.get_kline(
                        category="linear",
                        symbol=symbol,
                        interval=interval_str,
                        start=start_ms,
                        end=current_end,
                        limit=batch_limit
                    )
                    
                    if response['retCode'] != 0:
                        if "too many requests" in response['retMsg'].lower():
                            time.sleep(1)
                            continue
                        else:
                            break
                    
                    data = response['result']['list']
                    if not data:
                        break
                    
                    all_klines.extend(data)
                    pbar.update(len(data))
                    
                    # –ë–µ—Ä–µ–º —Å–∞–º—É—é —Å—Ç–∞—Ä—É—é —Å–≤–µ—á—É –≤ –ø–∞—á–∫–µ
                    oldest_ts = int(data[-1][0])
                    
                    # –ï—Å–ª–∏ –¥–æ—à–ª–∏ –¥–æ —Å—Ç–∞—Ä—Ç–∞ - –≤—ã—Ö–æ–¥–∏–º
                    if oldest_ts <= start_ms:
                        break
                    
                    current_end = oldest_ts - 1
                    time.sleep(0.05)
                    
                except Exception as e:
                    print(f"  ‚ùå –û—à–∏–±–∫–∞ {symbol}: {e}")
                    break
        
        if not all_klines:
            return None
        
        # –£–±–∏—Ä–∞–µ–º –¥—É–±–ª–∏–∫–∞—Ç—ã –∏ —Å–æ—Ä—Ç–∏—Ä—É–µ–º
        seen = set()
        unique_klines = []
        for k in reversed(all_klines):  # –ü–µ—Ä–µ–≤–æ—Ä–∞—á–∏–≤–∞–µ–º –≤ —Å—Ç–∞—Ä—ã–µ->–Ω–æ–≤—ã–µ
            ts = int(k[0])
            if ts not in seen and start_ms <= ts <= end_ms:
                seen.add(ts)
                unique_klines.append(k)
        
        # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º
        rows = []
        for k in unique_klines:
            ts = int(k[0])
            dt = datetime.fromtimestamp(ts / 1000)
            rows.append({
                'timestamp': dt,
                'open': float(k[1]),
                'high': float(k[2]),
                'low': float(k[3]),
                'close': float(k[4]),
                'volume': float(k[5]),
            })
        
        df = pd.DataFrame(rows)
        df['idx'] = df.index
        df['returns'] = df['close'].pct_change()
        df['range_pct'] = (df['high'] - df['low']) / df['low'] * 100
        df['funding_rate'] = 0.0001
        
        print(f"  ‚úÖ {symbol}: {len(df)} —Å–≤–µ—á–µ–π")
        return df

    
    def load_symbol_data(
        self,
        symbol: str,
        interval: str = '15m',
        start_date: str = None,
        end_date: str = None,
        use_cache: bool = True
    ) -> Optional[pd.DataFrame]:
        """
        –ö–≠–®: –æ–¥–∏–Ω —Ñ–∞–π–ª –Ω–∞ symbol+interval: cache/{symbol}_{interval}.parquet
        - –µ—Å–ª–∏ –∫—ç—à –µ—Å—Ç—å -> —á–∏—Ç–∞–µ–º –∏ –ø—Ä–æ—Å—Ç–æ —Ñ–∏–ª—å—Ç—Ä—É–µ–º –ø–æ –¥–∞—Ç–∞–º
        - –µ—Å–ª–∏ –∫—ç—à–∞ –Ω–µ—Ç -> –∫–∞—á–∞–µ–º –∑–∞ –∑–∞–ø—Ä–æ—à–µ–Ω–Ω—ã–π –¥–∏–∞–ø–∞–∑–æ–Ω –∏ —Å–æ—Ö—Ä–∞–Ω—è–µ–º
        """

        cache_file = self.cache_dir / f"{symbol}_{interval}.parquet"

        # –ì—Ä–∞–Ω–∏—Ü—ã –¥–∞—Ç
        start_dt = pd.to_datetime(start_date) if start_date else None
        end_dt = pd.to_datetime(end_date) if end_date else None

        # 1) –ß—Ç–µ–Ω–∏–µ –∫—ç—à–∞
        if use_cache and cache_file.exists():
            try:
                df = pd.read_parquet(cache_file)

                # –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è –ø–æ –¥–∞—Ç–∞–º (–±—ã—Å—Ç—Ä–æ)
                if start_dt is not None:
                    df = df[df["timestamp"] >= start_dt]
                if end_dt is not None:
                    df = df[df["timestamp"] <= end_dt]

                # –í–∞–∂–Ω–æ: –ø–æ—Å–ª–µ —Ñ–∏–ª—å—Ç—Ä–∞ –º–æ–∂–µ—Ç —Å—Ç–∞—Ç—å –ø—É—Å—Ç—ã–º
                if df is None or len(df) == 0:
                    return None

                # –ï—Å–ª–∏ —Ç–µ–±–µ –æ–±—è–∑–∞—Ç–µ–ª—å–Ω–æ –Ω—É–∂–Ω—ã —ç—Ç–∏ –∫–æ–ª–æ–Ω–∫–∏ –≤—Å–µ–≥–¥–∞:
                if "idx" not in df.columns:
                    df = df.reset_index(drop=True)
                    df["idx"] = df.index
                if "returns" not in df.columns:
                    df["returns"] = df["close"].pct_change()
                if "range_pct" not in df.columns:
                    df["range_pct"] = (df["high"] - df["low"]) / df["low"] * 100
                if "funding_rate" not in df.columns:
                    df["funding_rate"] = 0.0001

                return df

            except Exception:
                # –µ—Å–ª–∏ –∫—ç—à –±–∏—Ç—ã–π -> –ø—Ä–æ–±—É–µ–º —Å–∫–∞—á–∞—Ç—å –∑–∞–Ω–æ–≤–æ
                pass

        # 2) –ï—Å–ª–∏ –∫—ç—à–∞ –Ω–µ—Ç –∏–ª–∏ –æ–Ω –±–∏—Ç—ã–π -> –∫–∞—á–∞–µ–º
        df = self.get_klines(symbol, interval, start_date, end_date)
        if df is None or len(df) == 0:
            return None

        # 3) –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ –∫—ç—à (–æ–¥–∏–Ω —Ñ–∞–π–ª)
        if use_cache:
            try:
                df.to_parquet(cache_file, index=False)
            except Exception:
                pass

        return df

    
    def prepare_market_data(self, symbols: List[str], interval: str = '15m',
                       start_date: str = None, end_date: str = None,
                       max_workers: int = 5, use_cache: bool = True) -> Dict[str, pd.DataFrame]:
        """–ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω–∞—è –∑–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö"""
        
        market_data = {}
        total_symbols = len(symbols)
        
        print(f"\nüì• –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è {total_symbols} —Å–∏–º–≤–æ–ª–æ–≤...")
        print(f"   –≠—Ç–æ –∑–∞–π–º–µ—Ç –ø—Ä–∏–º–µ—Ä–Ω–æ {total_symbols * 2 // 60} –º–∏–Ω—É—Ç...\n")
        
        with ThreadPoolExecutor(max_workers=max_workers) as executor:
            future_to_symbol = {
                executor.submit(
                    self.load_symbol_data, symbol, interval, start_date, end_date, use_cache
                ): symbol for symbol in symbols
            }
            
            # –ï–¥–∏–Ω—ã–π –ø—Ä–æ–≥—Ä–µ—Å—Å-–±–∞—Ä –¥–ª—è –≤—Å–µ—Ö —Å–∏–º–≤–æ–ª–æ–≤
            with tqdm(total=total_symbols, desc="–û–±—â–∏–π –ø—Ä–æ–≥—Ä–µ—Å—Å", unit=" —Å–∏–º–≤–æ–ª") as pbar:
                for future in as_completed(future_to_symbol):
                    symbol = future_to_symbol[future]
                    try:
                        df = future.result()
                        if df is not None and len(df) > 0:
                            market_data[symbol] = df
                    except Exception as e:
                        pass  # –ò–≥–Ω–æ—Ä–∏—Ä—É–µ–º –æ—à–∏–±–∫–∏ –æ—Ç–¥–µ–ª—å–Ω—ã—Ö —Å–∏–º–≤–æ–ª–æ–≤
                    
                    pbar.update(1)
                    # –û–±–Ω–æ–≤–ª—è–µ–º –æ–ø–∏—Å–∞–Ω–∏–µ —Å —Ç–µ–∫—É—â–∏–º —Å–∏–º–≤–æ–ª–æ–º
                    pbar.set_description(f"–ó–∞–≥—Ä—É–∂–µ–Ω–æ: {len(market_data)}/{total_symbols}")
        
        print(f"\n‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(market_data)} —Å–∏–º–≤–æ–ª–æ–≤ –∏–∑ {total_symbols}")
        return market_data